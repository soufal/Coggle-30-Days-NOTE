{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3fa75b-c942-446b-bb79-22db944cbf2f",
   "metadata": {},
   "source": [
    "### 30 Days of Spark\n",
    "\n",
    "#### 任务1：PySpark数据处理\n",
    "\n",
    "*    步骤1：使用Python链接Spark环境\n",
    "*    步骤2：创建dateframe数据\n",
    "*    步骤3：用spark执行以下逻辑：找到数据行数、列数\n",
    "*    步骤4：用spark筛选class为1的样本\n",
    "*    步骤5：用spark筛选language >90 或 math> 90的样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e973dfb5-de06-4a9a-b4d7-bdb6ae50f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   002|    2|      87|  81|     90|    83|      83|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "|   004|    2|      65|  87|     94|    73|      88|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   006|    3|      84|  82|     85|    73|      99|\n",
      "|   007|    3|      56|  76|     63|    72|      87|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "|   009|    2|      63|  72|     87|    98|      64|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1、使用python链接Spark环境\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('pyspark') \\\n",
    "    .getOrCreate()\n",
    "# 原始数据 \n",
    "# 2、创建dataframe数据\n",
    "test = spark.createDataFrame([('001','1',100,87,67,83,98), ('002','2',87,81,90,83,83), ('003','3',86,91,83,89,63),\n",
    "                            ('004','2',65,87,94,73,88), ('005','1',76,62,89,81,98), ('006','3',84,82,85,73,99),\n",
    "                            ('007','3',56,76,63,72,87), ('008','1',55,62,46,78,71), ('009','2',63,72,87,98,64)],\n",
    "                             ['number','class','language','math','english','physic','chemical'])\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcaa9de-1d02-4ca9-b04b-282ba1114d18",
   "metadata": {},
   "source": [
    "##### 找到数据的行数和列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3102b9e-ec31-4b1b-b040-1737bffddd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of DataFrame's columns is 7\n"
     ]
    }
   ],
   "source": [
    "# 方法一\n",
    "column_len = len(test.columns)\n",
    "print(\"The length of DataFrame's columns is %s\" % column_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f224a4c-9eb3-431f-b589-102f945e7d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of DataFrame's rows is 9\n"
     ]
    }
   ],
   "source": [
    "# 方法一\n",
    "row_len = len(test.collect())\n",
    "print(\"The length of DataFrame's rows is %s\" % row_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95bc76d3-a7ee-4ae5-ad57-d757c74d6c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of DataFrame's rows is 9\n",
      "The length of DataFrame's columns is 7\n"
     ]
    }
   ],
   "source": [
    "# 方法二\n",
    "shape = (test.count(), len(test.columns))\n",
    "\n",
    "print(\"The length of DataFrame's rows is %s\" % shape[0])\n",
    "print(\"The length of DataFrame's columns is %s\" % shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051cb5a-6e4d-4347-bd9c-79bea241ae2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71d91095-874a-4826-9699-5f54957c0901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用spark筛选class为1的样本\n",
    "test.filter(test['class'] == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "552c7d42-be23-467b-bb54-0eed2427401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用spark筛选language>90 或math>90的样本\n",
    "test.filter((test['language'] > 90) | (test['math'] > 90)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5da766-53ad-4ff6-a584-6006b7069633",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "#### 任务2：PySpark数据统计\n",
    "\n",
    "* 步骤1：读取文件https://cdn.coggle.club/Pokemon.csv\n",
    "* 步骤2：将读取的进行保存，表头也需要保存\n",
    "* 步骤3：分析每列的类型，取值个数\n",
    "* 步骤4：分析每列是否包含缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0e0c0d5-6139-433d-9f0c-129189680d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "\n",
    "# 读取文件\n",
    "spark.sparkContext.addFile('https://cdn.coggle.club/Pokemon.csv')\n",
    "\n",
    "# 将读取的进行保存\n",
    "df = spark.read.csv(\"file://\"+SparkFiles.get(\"Pokemon.csv\"), header=True, inferSchema= True)\n",
    "df = df.withColumnRenamed('Sp. Atk', 'Sp Atk')\n",
    "df = df.withColumnRenamed('Sp. Def', 'Sp Def')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7cff14a-3cbe-4fdd-9acf-423872e2f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|                Name|Type 1|Type 2|Total| HP|Attack|Defense|Sp Atk|Sp Def|Speed|Generation|Legendary|\n",
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|           Bulbasaur| Grass|Poison|  318| 45|    49|     49|    65|    65|   45|         1|    false|\n",
      "|             Ivysaur| Grass|Poison|  405| 60|    62|     63|    80|    80|   60|         1|    false|\n",
      "|            Venusaur| Grass|Poison|  525| 80|    82|     83|   100|   100|   80|         1|    false|\n",
      "|VenusaurMega Venu...| Grass|Poison|  625| 80|   100|    123|   122|   120|   80|         1|    false|\n",
      "|          Charmander|  Fire|  null|  309| 39|    52|     43|    60|    50|   65|         1|    false|\n",
      "|          Charmeleon|  Fire|  null|  405| 58|    64|     58|    80|    65|   80|         1|    false|\n",
      "|           Charizard|  Fire|Flying|  534| 78|    84|     78|   109|    85|  100|         1|    false|\n",
      "|CharizardMega Cha...|  Fire|Dragon|  634| 78|   130|    111|   130|    85|  100|         1|    false|\n",
      "|CharizardMega Cha...|  Fire|Flying|  634| 78|   104|     78|   159|   115|  100|         1|    false|\n",
      "|            Squirtle| Water|  null|  314| 44|    48|     65|    50|    64|   43|         1|    false|\n",
      "|           Wartortle| Water|  null|  405| 59|    63|     80|    65|    80|   58|         1|    false|\n",
      "|           Blastoise| Water|  null|  530| 79|    83|    100|    85|   105|   78|         1|    false|\n",
      "|BlastoiseMega Bla...| Water|  null|  630| 79|   103|    120|   135|   115|   78|         1|    false|\n",
      "|            Caterpie|   Bug|  null|  195| 45|    30|     35|    20|    20|   45|         1|    false|\n",
      "|             Metapod|   Bug|  null|  205| 50|    20|     55|    25|    25|   30|         1|    false|\n",
      "|          Butterfree|   Bug|Flying|  395| 60|    45|     50|    90|    80|   70|         1|    false|\n",
      "|              Weedle|   Bug|Poison|  195| 40|    35|     30|    20|    20|   50|         1|    false|\n",
      "|              Kakuna|   Bug|Poison|  205| 45|    25|     50|    25|    25|   35|         1|    false|\n",
      "|            Beedrill|   Bug|Poison|  395| 65|    90|     40|    45|    80|   75|         1|    false|\n",
      "|BeedrillMega Beed...|   Bug|Poison|  495| 65|   150|     40|    15|    80|  145|         1|    false|\n",
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa712b-4a9d-4c82-ac45-cebb6eb41cbd",
   "metadata": {},
   "source": [
    "##### 分析每一列的类型和取值个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f194a853-a354-4f6b-98bd-d91ab4e680d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Type 1', 'string'),\n",
       " ('Type 2', 'string'),\n",
       " ('Total', 'int'),\n",
       " ('HP', 'int'),\n",
       " ('Attack', 'int'),\n",
       " ('Defense', 'int'),\n",
       " ('Sp Atk', 'int'),\n",
       " ('Sp Def', 'int'),\n",
       " ('Speed', 'int'),\n",
       " ('Generation', 'int'),\n",
       " ('Legendary', 'boolean')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方法一\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "752fd600-6158-429b-a815-e7e6918df206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Type 1: string (nullable = true)\n",
      " |-- Type 2: string (nullable = true)\n",
      " |-- Total: integer (nullable = true)\n",
      " |-- HP: integer (nullable = true)\n",
      " |-- Attack: integer (nullable = true)\n",
      " |-- Defense: integer (nullable = true)\n",
      " |-- Sp Atk: integer (nullable = true)\n",
      " |-- Sp Def: integer (nullable = true)\n",
      " |-- Speed: integer (nullable = true)\n",
      " |-- Generation: integer (nullable = true)\n",
      " |-- Legendary: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 方法二\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bdb5682-b73a-4a8e-b22c-baabbf421cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75f981cf-9dd7-4754-b297-8f21d733fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方法一：以去重的思想去分析列中的取值个数\n",
    "# 可采用两种方法\n",
    "\n",
    "# df.select('Name').drop_duplicates().count()\n",
    "\n",
    "df.select('Name').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16d20aec-576a-4f92-a05c-05cd4184c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06ca068a-5a8c-48d0-b967-2a7d2cb14cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'Type 1',\n",
       " 'Type 2',\n",
       " 'Total',\n",
       " 'HP',\n",
       " 'Attack',\n",
       " 'Defense',\n",
       " 'Sp Atk',\n",
       " 'Sp Def',\n",
       " 'Speed',\n",
       " 'Generation',\n",
       " 'Legendary']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ee6ad80-0396-480d-9e0e-b892452667dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列 Name 的取值为：799\n",
      "列 Type 1 的取值为：18\n",
      "列 Type 2 的取值为：19\n",
      "列 Total 的取值为：200\n",
      "列 HP 的取值为：94\n",
      "列 Attack 的取值为：111\n",
      "列 Defense 的取值为：103\n",
      "列 Sp Atk 的取值为：105\n",
      "列 Sp Def 的取值为：92\n",
      "列 Speed 的取值为：108\n",
      "列 Generation 的取值为：6\n",
      "列 Legendary 的取值为：2\n"
     ]
    }
   ],
   "source": [
    "for i in columns_list:\n",
    "    value = df.select(i).drop_duplicates().count()\n",
    "    print(\"列 %s 的取值为：%s\" % (i, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "48fb1be7-dbea-4646-b452-e9e4454b4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Name=799)]\n",
      "[Row(Type 1=18)]\n",
      "[Row(Type 2=18)]\n",
      "[Row(Total=200)]\n",
      "[Row(HP=94)]\n",
      "[Row(Attack=111)]\n",
      "[Row(Defense=103)]\n",
      "[Row(Sp Atk=105)]\n",
      "[Row(Sp Def=92)]\n",
      "[Row(Speed=108)]\n",
      "[Row(Generation=6)]\n",
      "[Row(Legendary=2)]\n"
     ]
    }
   ],
   "source": [
    "# 方法二：使用聚合函数 countDistinct\n",
    "import pyspark.sql.functions as F\n",
    "for i in columns_list:\n",
    "    print(df.agg(F.countDistinct(i).alias(i)).collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f89a3f-766a-4a42-95ab-311386e94a80",
   "metadata": {},
   "source": [
    "> 会发现上面的两个结果中，对于列“Type 2”的结果有所不同， 检查数据后发现是因为“Type 2”中包含有却是之的数据，在第一种方法中，会将空值“NULL”当作一个值去统计，而使用`countDisinct`函数，他会排除出空值数据后再进行统计。\n",
    "> 下面先分析每列中是否包含有缺失值，然后再重新使用方法一统计。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69dcf6d-7fc9-4355-9179-f360829cd1c8",
   "metadata": {},
   "source": [
    "##### 分析每列是否包含缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6f38457-29ae-4052-865e-49eb763802fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列 Name 的取值为：799\n",
      "列 Type 1 的取值为：18\n",
      "列 Type 2 的取值为：18\n",
      "列 Total 的取值为：200\n",
      "列 HP 的取值为：94\n",
      "列 Attack 的取值为：111\n",
      "列 Defense 的取值为：103\n",
      "列 Sp Atk 的取值为：105\n",
      "列 Sp Def 的取值为：92\n",
      "列 Speed 的取值为：108\n",
      "列 Generation 的取值为：6\n",
      "列 Legendary 的取值为：2\n"
     ]
    }
   ],
   "source": [
    "# 增加对每一列进行去重处理后再统计取值\n",
    "for i in columns_list:\n",
    "    value = df.select(i).dropna().drop_duplicates().count()\n",
    "    print(\"列 %s 的取值为：%s\" % (i, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4282d716-d130-4162-8186-01b3906e42d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------------------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|Name|Type 1|             Type 2|Total| HP|Attack|Defense|Sp Atk|Sp Def|Speed|Generation|Legendary|\n",
      "+----+------+-------------------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "| 0.0|   0.0|0.48250000000000004|  0.0|0.0|   0.0|    0.0|   0.0|   0.0|  0.0|       0.0|      0.0|\n",
      "+----+------+-------------------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#统计每列数据缺失占比情况\n",
    "df.agg(*[(1 - (F.count(c) / F.count('*'))).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83c280e8-5e00-41c9-8ff5-18c43b9595cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析每列中缺失值个数\n",
    "df_agg = df.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14853a8a-4db7-45bc-9d1b-c3d1798873ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|Name|Type 1|Type 2|Total| HP|Attack|Defense|Sp Atk|Sp Def|Speed|Generation|Legendary|\n",
      "+----+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|   0|     0|   386|    0|  0|     0|      0|     0|     0|    0|         0|        0|\n",
      "+----+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
